# This is an example script of creating input file for conregistration.py.
# The input file is a text file and contains comma-separated values.
# Each row has five fields -- index, longitude, latitude, time, and plate id.

# The script contains hardcoded file names.
# You should only use this script as an example and modify the example to prepare input data suitable to your research.

import geopandas as gpd
import numpy as np
from numpy import ones, vstack
from numpy.linalg import lstsq
import os, sys
# import pandas as pd
# from parameters import parameters
import shapefile
# from shapely import geometry
from shapely.geometry import LineString, Point, shape
import Utils

# the age is a floating-point number. map the floating-point number to the nereast integer time in the range
def get_time_from_age(ages, start, end, step):
    ret = []
    times = range(start, end+1, step)
    
    for age in ages:
        age = float(age)
        if age <= start:
            ret.append(start)
        elif age >= end:
            ret.append(end)
        else:
            idx = int((age - start)//step)
            mod = (age - start)%step
            if not (mod < step/2.):
                idx = idx+1 
            ret.append(times[idx])
            
    return ret

def process_real_deposits(deposit_path, start_time, end_time, time_step): # path to the shapefile of mineral occurrences
    if not os.path.isfile(deposit_path):
        sys.exit('File not found!')
    reader = shapefile.Reader(deposit_path)
    recs = reader.records()
    min_occ_num = len(recs)
    # longitude
    lons = np.array(recs)[:, 3]
    # latitude
    lats = np.array(recs)[:, 4]
    # time
    times = get_time_from_age(np.array(recs)[:, 14], start_time, end_time, time_step) # get integer ages
    # plate id
    plate_ids = Utils.get_plate_id(lons, lats)
    # index, lon, lat, time, plate id
    data = []
    
    for i in range(min_occ_num):
        data.append([i, lons[i], lats[i], times[i], plate_ids[i]])
    data = np.array(data)
    
    return data

# genrate buffer zones surrounding polylines (segment by segment)_v5.0_similar to the previous version but considers aspect to generate buffer zones
def generate_buffer_zones(subduction_geoms, radius): # subduction_geoms generated by Utils.get_subduction_geometries()
    lines_list = []
    buffer_zones_list = []
    buffer_zones_df_list = []

    # add an appropriate vertex to the lines on anti-meridian
    for geom, aspect in subduction_geoms:
        index_list = []
        vertex_list = []
        xy = geom.to_lat_lon_array()
        num_xy = xy.shape[0]
        for i in range(num_xy-1):
            if xy[i, 1] * xy[i+1, 1] < 0 and 180 - abs(xy[i, 1]) < abs(xy[i, 1]):
                index_list.append(i+1)
                m = (xy[i+1, 0] - xy[i, 0]) / (xy[i+1, 1] - xy[i, 1])
                b = xy[i, 0] - (m * xy[i, 1])
                pos_vertex = [m*180+b, 180]
                neg_vertex = [m*-180+b, -180]
                if xy[i, 1] > 0:
                    vertex_list.append([pos_vertex, neg_vertex])
                else:
                    vertex_list.append([neg_vertex, pos_vertex])

        if len(index_list) > 0:
            xy = np.insert(xy, index_list, np.array(vertex_list[0]), 0)

        # split the line where it passes over anti-meridian
        index_list = []
        num_xy = xy.shape[0]
        for i in range(num_xy-1):
            if xy[i, 1] * xy[i+1, 1] < 0 and 180 - abs(xy[i, 1]) < abs(xy[i, 1]):
                index_list.append(i+1)
        xy_split = np.split(xy, index_list)
        xy_split.append(aspect)
        lines_list.append(xy_split)

    for line in lines_list:
        aspect = line[-1]
        for i in range(len(line)-1):
            buffer_zones = []
            for j in range(line[i].shape[0]-1):
                buffer_zone = gpd.GeoSeries(LineString([(line[i][j, 1], line[i][j, 0]), (line[i][j+1, 1], line[i][j+1, 0])]), crs='EPSG:4326').buffer(-1*aspect*radius, cap_style=2, single_sided=True)
                buffer_zones.append(buffer_zone)
            
            # convert the list of geoseries objects to a geodataframe
            buffer_zones_df = gpd.GeoDataFrame(gpd.GeoSeries(buffer_zones[0]))
            for k in range(1, len(buffer_zones)):
                buffer_zones_df.loc[k] = gpd.GeoSeries(buffer_zones[k])
            buffer_zones_df = buffer_zones_df.rename(columns={0: 'geometry'}).set_geometry('geometry')
            
            for m in range(buffer_zones_df.shape[0]):
                buffer_zone_dis_ch = buffer_zones_df.iloc[m:m+2].dissolve().convex_hull
                buffer_zones_list.append(buffer_zone_dis_ch)
            buffer_zones_df_list.append(buffer_zones_df)
    
    buffer_zones_list_df = gpd.GeoDataFrame(gpd.GeoSeries(buffer_zones_list[0]))
    for m in range(1, len(buffer_zones_list)):
        buffer_zones_list_df.loc[m] = gpd.GeoSeries(buffer_zones_list[m])
    buffer_zones_list_df = buffer_zones_list_df.rename(columns={0: 'geometry'}).set_geometry('geometry')
    buffer_zones_list_dis = buffer_zones_list_df.dissolve()

    return buffer_zones_df_list, buffer_zones_list_dis

# generate random samples inside buffer zones at a specific time step
def generate_random_samples(buffer_zone, time, num_samples, rand_factor):
# rand_factor: a factor which is multiplied by the number of samples (num_samples) and
# determines the total number of samples to be generated from which random samples are selected
    
    bounds = buffer_zone.bounds
    x_min = bounds.loc[0]['minx']
    x_max = bounds.loc[0]['maxx']
    y_min = bounds.loc[0]['miny']
    y_max = bounds.loc[0]['maxy']

    if x_min < -180:
        x_min = -180
    if x_max > 180:
        x_max = 180
    if y_min < -90:
        y_min = -90
    if y_max > 90:
        y_max = 90

    rand_x_list = []
    rand_y_list = []
    
    for n in range(1, rand_factor):
        if len(rand_x_list) < num_samples:
            rand_x = np.random.uniform(low=x_min, high=x_max, size=n*num_samples)
            rand_y = np.random.uniform(low=y_min, high=y_max, size=n*num_samples)
            for x, y in zip(rand_x, rand_y):
                if len(rand_x_list) == num_samples:
                    break
                p = Point((x, y))
                if p.within(buffer_zone.geometry[0]):
                    rand_x_list.append(x)
                    rand_y_list.append(y)
        else:
            break
    
    plate_ids = Utils.get_plate_id(rand_x_list, rand_y_list)
    # index, lon, lat, time, plate id
    data = []
    for i in range(num_samples):
        data.append([rand_x_list[i], rand_y_list[i], time, plate_ids[i]])
    data = np.array(data)
    
    return data

# generate sampling points inside buffer zones at a specific time step
def generate_samples(buffer_zone, dist_x, dist_y, time):
    bounds = buffer_zone.bounds
    x_min = bounds.loc[0]['minx']
    x_max = bounds.loc[0]['maxx']
    y_min = bounds.loc[0]['miny']
    y_max = bounds.loc[0]['maxy']
    
    if x_min < -180:
        x_min = -180
    if x_max > 180:
        x_max = 180
    if y_min < -90:
        y_min = -90
    if y_max > 90:
        y_max = 90
    
    x = np.arange(x_min, x_max, dist_x)
    y = np.arange(y_min, y_max, dist_y)
    nx = len(x)
    ny = len(y)
    xs, ys = np.meshgrid(x, y)

    sample_x = []
    sample_y = []
    sample_mask = []
    
    for xx, yy in zip(xs.flatten(), ys.flatten()):
        p = Point((xx, yy))
        if p.within(buffer_zone.geometry[0]):
            sample_x.append(xx)
            sample_y.append(yy)
            sample_mask.append(True)
        else:
            sample_mask.append(False)
    
    mask_x = np.array([xs.flatten()]).T
    mask_y = np.array([ys.flatten()]).T
    sample_mask = np.array([sample_mask]).T
    mask_coords = np.hstack((mask_x, mask_y, sample_mask))
    
    plate_ids = Utils.get_plate_id(sample_x, sample_y)

    # index, lon, lat, time, plate id
    sample_data = []
    for i in range(len(sample_x)):
        sample_data.append([i, sample_x[i], sample_y[i], time, plate_ids[i]])
    sample_data = np.array(sample_data)
    
    return sample_data, mask_coords, nx, ny

def generate_trench_points(start_time, end_time, time_step):
    trench_data=[]
    trench_points = Utils.get_trench_points(0,-85,5,-70,-60) #subduction points in south america 
    i=0
    
    for t in range(start_time, end_time, time_step):
        for index, p in trench_points.iterrows():
            trench_data.append([i, p['trench_lon'], p['trench_lat'], t, p['trench_pid']]) 
            i+=1
            
    return trench_data    

def save_data(data,fn):
    # data are ready and write them to file
    with open(fn,'w+') as f:
        f.write('index,lon,lat,age,plate_id\n')
        for row in data:
            #print(row)
            if row:
                f.write('{0:d}, {1:.2f}, {2:.2f}, {3:d}, {4:d}'.format(
                    int(row[0]),float(row[1]),float(row[2]),int(row[3]),int(row[4])))
            f.write('\n')

    print(f'The data have been written into {fn} successfully!')                               

# if __name__ == '__main__':
#     start_time = parameters['time']['start']
#     end_time = parameters['time']['end']
#     time_step =  parameters['time']['step']
#     deposit_path = parameters['deposit_path']
#     polygon_path = parameters['region_of_interest_polygon']
#     # convergence_file = parameters['convergence_data_dir']+parameters['convergence_data_filename_prefix']+'_0.00.csv'
#     num_features = num_features = len(parameters['selected_features'])
#     map_extent = parameters['map_extent']
#     dist_x = 1
#     dist_y = 1

#     data = process_real_deposits(deposit_path, start_time, end_time, time_step)
#     random_data = generate_random_samples(polygon_path, start_time, end_time, num_features)
#     sample_data = generate_samples(polygon_path, dist_x, dist_y, start_time, end_time, map_extent)
#     trench_data = generate_trench_points(start_time, end_time, time_step)

#     all_data = data+random_data+trench_data
#     for i in range(len(all_data)):
#         all_data[i][0] = i # assign correct indices

#     save_data(all_data, 'coregistration_input_data_example.csv')
